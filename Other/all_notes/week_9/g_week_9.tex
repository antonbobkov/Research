\Week{ Week 9 }
\NotesBy{Notes for today by John Lensmire.}
\Day{ Monday 12-1-2014 }

\begin{corollary}[Weierstrass Preparation] % ==== Corollary 9.4 (Weierstrauss Preparation) ==== 

Let $f\in K[[X,T]]$ be regular of order $d$ in $T$.
Then $f\in K[[X,T]]^\times$ and $W\in K[[X]][T]$ is monic of degree $d$ in $T$.
 \end{corollary}

\begin{proof} %\WikiBold{Proof:} 

Using Theorem \ref{9.3}, we can write $T^d = Qf+R$ where $Q\in K[[X,T]], R\in K[[X]][T], \mathrm{deg}_TR < d$.

Let $x=0$ to get
$$T^d = \left( \sum_i Q_i(0) T^i \right) (f_d(0) + \textrm{ terms of higher order} )
+ R_0(0) + R_1(0) T + \cdots + R_{d-1}(0) T^{d-1}.$$
Looking at the coefficient of $T^d$, we have $1 = Q_0(0) f_d(0)$.
This implies $Q_0 \in K[[X]]^\times$ and thus $Q\in K[[X,T]]^\times$.

Hence, we have $f = uW$ where $u = Q^{-1}$ and $W = T^d - R$.

Uniqueness follows from the uniqueness in Theorem \ref{9.3} (details are left as an exercise.)
 \end{proof}

\begin{remark}
The above proof shows that we can take $W$ to be a Weierstrauss polynomial, i.e. a monic polynomial
$W = T^d + W_{d-1} T^{d-1} + \cdots + W_0$ where $W_0,\ldots, W_{d-1}\in \mathfrak{o}[[X]]$.
\end{remark}

\begin{corollary} % ==== Corollary 9.5 ==== 
Suppose $K$ is infinite. Then the ring $K[[X]]$ is noetherian.
 \end{corollary}

\begin{proof} %\WikiBold{Proof:} 
We proceed by induction on $m$.

If $m=0$, $K$ is a field, hence noetherian.

From $m$ to $m+1$:
Let $\{0\} \neq I \subset K[[X,T]]$ be an ideal.
Take $f\in I\setminus \{0\}$, after replacing $I,f$ by images under a suitable automorphism of $K[[X,T]]$
(see last time) we can assume that $f$ is regular in $T$ of some order $d$.
Then each $g\in I$ can be written as $g = qf + r$, where $q\in K[[X,T]]$ and $r\in A[T]$ is of degree $<d$ ($A = K[[X]]$).
Hence, $r\in I \cap (A + AT + \cdots + AT^{d-1})$. By induction $J:= I\cap (A + AT + \cdots + AT^{d-1})$ is a finitely generated $A$-module.

Therefore, $I$ is generated by $f$ and the (finitely many) generators of $J$, as needed.
 \end{proof}

\section{Convergent Power Series }

A {\em polyradius is a vector} $r = (r_1,\ldots, r_m)\in (R^{\geq 0})^m$.
Given polyradii $r,s$ we write
\begin{enumerate}
  \item  $r\leq s \Leftrightarrow r_i \leq s_i$ for each $i$.
  \item  $r < s \Leftrightarrow r_i < s_i$ for each $i$.
  \item  $r^i = r_1^{i_1}\cdots r_m^{i_m}$ for $i = (i_1,\ldots, i_m)\in \mathbb{N}^m$.
\end{enumerate}

Given a polyradius $r$ and $a\in \mathbb{C}^m$, $D_r(a):= \{x\in \mathbb{C}^m |\ |x_i - a_i| < r_i
\textrm{ for } i = 1,\ldots,m$, called the open \textit{polydisk centered at $a$ with polyradius $r$}.
Its closure, \textit{the closed polydisk centered at $a$ with polyradius $r$}, is $\overline{D_r}(a) = \{x | \ |x_i - a_i| \leq r_i\}$.

For $f\in \mathbb{C}[[X]]$, define $\|f\|_r := \sum_i |f_i| r^i \in \mathbb{R}^{\leq 0} \cup \{+\infty\}$.
Writing $\|\cdot \| = \|\cdot \|_r$, it is easy to verify:
\begin{enumerate}
  \item  $\|f\| = 0 \Leftrightarrow f = 0$.
  \item  $\|c f\| = |c| \cdot \|f\|$ for $c\in \mathbb{C}$.
  \item  $\|f + g\| \leq \|f\| + \|g\|$.
  \item  $\|f\cdot g\| \leq \|f\| \cdot \|g\|$.
  \item  $\|X^i f\| = r^i \|f\|$.
  \item  $r\leq s \Rightarrow \|f\|_r \leq \|f\|_s$.
\end{enumerate}

\begin{definition} % ==== Definition 10.1 ==== 
$\mathbb{C}\{X\}_r := \{f\in \mathbb{C}[[X]] |\ \|f\|_r < +\infty \}$
 \end{definition}

\begin{lemma}\ % ==== Lemma 10.2 ==== 
\begin{enumerate}
  \item  $\mathbb{C} \{X\}_r$ is a subalgebra of $\mathbb{C}[[X]]$ containing $C[X]$.
  \item  $\mathbb{C} \{X\}_r$ is complete with respect to the norm $\|\cdot\|_r$.
\end{enumerate}
 \end{lemma}

\begin{proof} %\WikiBold{Proof:} 
1. is clear. 2. is routine using a "Cauchy Estimate": for every $i\in \mathbb{N}^m$, $|f_i|\leq \|f\|_r/r^i$,
and is left as an exercise.
 \end{proof}

Each $f\in\mathbb{C}\{X\}_r$ gives rise to a function $\overline{D_r}(0)\rightarrow\mathbb{C}$ as follows:
For $x\in\overline{D_r}(0)$, the series $\sum_i f_i x^i$ converges absolutely to a complex number $f(x)$.
This function $x\mapsto f(x)$ is continuous (as it is the limit of uniformly continuous functions).

For $f\in \mathbb{C}[[X,Y]]$, $f = \sum_{j\in \mathbb{N}^n} f_j(X) Y^j$, 
and $(r,s)\in (\mathbb{R}^{\geq 0})^{m+n}$ a polyradius, we have (from the definitions)
$\|f\|_{(r,s)} = \sum_j \|f_j\|_r s^j$.
Hence, $f\in \mathbb{C}\{X,Y\}_{(r,s)}$ and in particular $f_j\in \mathbb{C}\{X\}_r$ for all $j$.
Further, we have,
for $x\in \overline{D_r}(0)$, $f(x,y):= \sum_j f_j(X)Y^j\in \mathbb{C}\{Y\}_s$,
and for $(x,y)\in \overline{D_{(r,s)}}(0)$, $f(x,y) = \left( \sum_j f_j(X)Y^j\right)(y) = \sum_j f_j(x)y^j$.

\begin{lemma} % ==== Lemma 10.3 ==== 

The map that sends $f\in \mathbb{C}\{X\}_r$ to $f_r$ given by $x\mapsto f(x)$ is an injective ring morphism:
$$\mathbb{C}\{X\}_r \rightarrow \{\textrm{ ring of continuous functions } \overline{D_r}(0) \rightarrow \mathbb{C}\}$$
Further, $\|f_r\|_{\mathrm{sup}} \leq \|f\|_r$.
 \end{lemma}

\begin{proof} %\WikiBold{Proof:} 

All claims follow from definitions directly except injectivity. By induction on $m$, we show:
$f\in \mathbb{C}\{X\}_r\setminus \{0\}$ implies $f_r$ does not vanish identically on any open neighborhood of $0\in \mathbb{C}^m$.

If $m=1$, write $f = X^d (f_d + f_{d+1} X + \cdots )$, where $f_i\in \mathbb{C}, f_d\neq 0$.

For $|x|\leq r$, the series $f_d + f_{d+1}X + \cdots $ converges to a continuous function of $X$.
This function takes value $f_d\neq 0$ at $x=0$, hence is non-zero in a neighborhood around $0$.

For $m\geq 2$, write $f = \sum_i f_i(X') X_m^i$, where $X' = (X_1,\ldots, X_{m-1})$, $f_i \in \mathbb{C}\{X'\}_{r'}$
with $r' = (r_1,\ldots, r_{m-1})$.
Then $\|f\|_r = \sum_i \|f_i\|_{r'} r_m^i$ and $f(x) = \sum_i f_i(X')X_m^i$ for $X = (X',X_m)\in \overline{D_r}(0)$.
Fix $j$ such that $f_j(X') = 0$. By the induction hypothesis, there are $X'\in \mathbb{C}^{m-1}$ as close as we want to $0$
such that $f_j(X')\neq 0$. For such an $X'$ (as in the $m=1$ case), we have $f(X',X_m)\neq 0$ for all sufficiently small $X_m$.
 \end{proof}

\NotesBy{Notes for today by Assaf Shani}
\Day{ Wednesday 12-3-2014 }

\WikiBoldItalic{Coming soon}

\NotesBy{Notes for today by Tyler Arant}
\Day{ Friday 12-5-2014 }

\textbf{Correction for proof of Weierstrass Preparation.} We had $f, g\in \mathds{C}\{X, T\}$, $f$ regular of order $d$, and
$$F=u^{-1}\sum_{i<d}f_iT^i, \quad u=f_d + f_{d+1}T+ \cdots \in \mathds{C}\{X, T\}^\times.$$
Choose $(r', r_{m+1})\in (\mathds{R}^{>0})^{m+1}$ such that
$$\|g\|_r, \|u^{-1}\|_r, \|f_0\|_{r'}, \dots, \|f_{d+1}\|_{r'}<\infty.$$
Then, we can achieve
$$\|F\|_r\leq \|u^{-1}\|\cdot \sum_{i<d}\|f_i\|_{r'}r^i_{m+1}<r^d_{m+1},$$
since the $f_i$ vanish at $0$ we can make the norms as small as we want by choosing $r'$ small enough.\\

Let $R\subset S$ be an extension of commutative rings.

\begin{definition} $S$ is \textit{flat over} $R$ if each solution in $S$ to an equation
\begin{equation} r_1x_1+\cdots + r_n x_n=0 \qquad (r_i\in R) \tag{$*$}\end{equation}
is an $S$-linear combination of solutions in $R$. \end{definition}

\begin{lemma} If $S$ free as an $R$-module, then $S$ is flat over $R$. \end{lemma}

\begin{proof} Let $s=(s_1, \dots, s_n)\in S^n$ be a solution to $(*)$.  Take $R$-linearly independent $e_1, \dots, e_k\in S$ such that
$$s_i=\sum_j w_{ij} e_j \qquad (w_{ij}\in R).$$
Put $w_j=(w_{1j}, \dots, w_{nj})$.  Then $w_j$ is a solution to $(*)$ and $s=\sum_j e_jw_j.$
\end{proof}

We give some examples
\begin{enumerate}%[$\bullet$]
\item If $R$ is a field, then each $S$ is flat over $R$.  
\item $S=R[X_1, \dots, X_n]$ flat over $R$.
\end{enumerate}

\begin{lemma} Suppose $S$ is flat over $R$.  Then each solution in $S$ to a system
$$r_{i1}x_1 + \cdots + r_{in}x_n=0 \qquad (i=1, \dots, m ; r_{ij}\in R)$$
is an $S$-linear combination of solutions in $R$. \end{lemma}

\begin{proof} By induction on $m$.  \end{proof}

\begin{definition} We say that $S$ is \textit{faithfully flat} over $R$ if
\begin{enumerate}%[$\bullet$]
\item $S$ is flat over $R$.
\item Each equation 
$$r_1x_1+\cdots +r_nx_n=1 \qquad (r_i\in R)$$
that has a solution in $S$ has a solution in $R$. \end{enumerate}
\end{definition}

\begin{lemma} Suppose $S$ is flat over $R$.  The following are equivalent.
\begin{enumerate}[(1)]
\item $S$ is faithfully flat over $R$.
\item For each maximal ideal $\mathfrak{m}$ of $R$, we have $\mathfrak{m}S\neq S$.
\item Each system 
\begin{equation} \sum_{j=1}^n r_{ij}x_j = t_i \qquad (i=1, \dots, m ; r_{ij}, t_i\in R) \tag{$*$} \end{equation}
that has a solution in $S$ has a solution in $R$. 
\end{enumerate} \end{lemma}

$(1)\implies(2)$: Suppose, by means of contradiction, that $\mathfrak{m}S=S$.  Then, there are $r_i\in \mathfrak{m}$ and $s_i\in S$ such that
$$r_1s_1+\cdots + r_n s_n = 1,$$
i.e., $s=(s_1, \dots, s_n)$ is a solution to the equation
$$r_1x_1 + \cdots + r_n x_n = 1.$$
Since $S$ is faithfully flat over $R$, there is a solution $w=(w_1, \dots, w_n)$ so that
$$1= r_1w_1+\cdots + r_n w_n \in \mathfrak{m},$$
which is a contradiction. 

$(2)\implies (1)$:  Suppose $S$ is not faithfully flat over $R$; then, there are $r_i\in R$ such that
$$r_1x_1+\cdots + r_n x_n=1$$
has a solution $s$ in $S$ but not a solution in $R$.  Then the ideal $\mathfrak{a}=(r_1, \dots, r_n)$ in $R$ is proper.  Let $\mathfrak{m}$ be an ideal in $R$ that contains $\mathfrak{a}$. Then, $\mathfrak{m}S=S$ since
$$1=r_1s_1+\cdots r_n s_n \in \mathfrak{m}S.$$

$(3)\implies (1)$ trivially.

$(1)\implies (3)$: Suppose $(*)$ has a solution $s=(s_1, \dots, s_n)\in S^n$.  Then, $(1, s)= (1, s_1, \dots, s_n)$ is a solution to the homogenous system
\begin{align*} -t_1x_0+\sum_{j=1}^n r_{1j}x_j &=  0  \\
				&\vdots     \tag{$**$} \\
		-t_mx_0 + \sum_{j=1}^n r_{mj}x_j  & =  0 \end{align*}
Since $S$ is flat over $R$, $(1, s)$ is an $S$-linear combination of solutions $(u_1, v_1), \dots, (u_k, v_k)$ in $R^{1+n}$. So,
$$(1, s) = w_1(u_1, v_1) + \cdots + w_k(u_k, v_k) \qquad (w_i\in S),$$
hence
$$1= w_1 u_1 + \cdots + w_k u_k.$$
By $(1)$, there exists $\omega_1, \dots, \omega_k\in R$ such that
$$1= \omega_1u_1 + \cdots + \omega_k u_k.$$
Then, $\omega_1v_1+\cdots + \omega_k v_k\in R^n$ solves $(*)$. 



\begin{theorem} $\mathds{C}[[X]]$ is faithfully flat over $\mathds{C}\{X\}$. \end{theorem}

\begin{proof}[Proof sketch] We proceed by induction on the number of variable.  Consider
\begin{equation}f_1y_1+\cdots + f_n y_n = 0 \qquad (f_i\in \mathds{C}\{X, T\}. \tag{$*$} \end{equation}
We may assume that all $f_i$, if nonzero, are regular in $T$.  Then, apply Weierstass Preparation in $\mathds{C}\{X, T\}$ to the $f_i\neq 0$.  Then, we can assume that the $f_i\neq0$ are Weierstrass polynomials: $f_i\in \mathds{C}\{X\}[T]$ monic of some degree $d_i$.  Set
$$z_2 = \left [ \begin{array}{c} f_2 \\ -f_1 \\ 0 \\ \vdots \\ 0 \end{array} \right ], z_3= \left [ \begin{array}{c} f_3 \\ 0 \\ -f_1 \\ 0 \\ \vdots \\ 0 \end{array} \right ], \cdots, z_n= \left [ \begin{array}{c} f_n \\ 0 \\ \vdots \\ 0 \\ -f_1\end{array} \right ],$$
which together is a solution of $(*)$.  We have $y_i=q_if_1+r_i$, where $q_i\in \mathds{C}[[X, T]]$, and $r_i\in \mathds{C}[[X]][T]$ is of degree $<d_1$.  Then consider
$$y+q_2z_2= \left [ \begin{array}{c} * \\ r_2 \\ y_3 \\ \vdots \\ y_n \end{array} \right ], \dots , y+q_2z_2+\cdots f_ny_n= \left [ \begin{array}{c} * \\ r_2\\ r_3 \\ \vdots \\ r_n \end{array} \right ],$$
and conclude that we can assume $y_2, \dots, y_n\in \mathds{C}[[X]][T]$.   We have
$$g:= f_1y_1 = -(f_2y_2+\cdots + f_ny_n)\in \mathds{C}\{X\}[T].$$
We can find $h, r$ with $g=f_1h+r$ with $h, r\in \mathds{C}[[X]][T]$, $\deg r<d_1$.  So, $g=f_1y_1+0$ in $\mathds{C}[[X, T]]$, hence $r=0$ and $y_1=h\in \mathds{C}[[X]][T]$.  This reduces the proof to showing: $R\subset S$ flat $\implies R[T]\subset S[T]$ flat.
\end{proof}

\section{Restricted Analytic Functions}

\begin{lemma}[Taylor expansion] Suppose $f\in \mathds{C}\{X\}_s$ and $b\in D_s(0)$, $j\in \mathds{N}^m$.  Then,
\begin{enumerate}[(1)]
\item $\partial^j f :=\left (\frac{\partial}{\partial X_1} \right )^{j_1} \cdots \left (\frac{\partial}{\partial X_m} \right )^{j_m}f\in \mathds{C}\{X\}_r$ for all $r<s$.
\item $(\partial^jf)(b):= \sum_{i\geq j} f_i \frac{i!}{(i-j)!}b^{i-j}$ converges absolutely.  
\item $\sum_j \frac{1}{j!} (\partial^jf)(b)X^j\in \mathds{C}\{X\}_{s(b)}$, where
$$s(b)=(s_1-|b_1|, \dots, s_m-|b_m|),$$
and
$$f(x+b) = \sum_j\frac{1}{j!}(\partial^jf)(b)x^j \qquad (x\in \overline{D_{s(b)}}(0)).$$
\end{enumerate}
\end{lemma}

\begin{proof} \begin{enumerate}[(1)]
\item By induction on $|j|$.  The case $\frac{\partial}{\partial x+k}$ follows from Abel's Lemma: a finite bound on $|f_i|s^i$ gives a finite bound on $i_k|f_i|r^{i-e_k}$ (for given $r<s$, with $e_k$ is the $k^th$ standard basis vector).  
\item Follows easily from $(1)$.
\item Left as an exercise using $(2)$ and multivariate binomial theorem. 
\end{enumerate}\end{proof}

